{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Hours: 1.000000\n",
      "Prediction Window: 24\n",
      "Sequence Length: 168\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "\n",
    "# Average window_stride elements together to form a single row\n",
    "window_stride = 12\n",
    "\n",
    "sample_hours = window_stride / 12.0\n",
    "print(\"Sample Hours: %f\" % sample_hours)\n",
    "\n",
    "# Number of future samples to mean for prediction\n",
    "prediction_window = int(24 / sample_hours)\n",
    "print(\"Prediction Window: %d\" % prediction_window)\n",
    "\n",
    "# Length of the windowed sequence\n",
    "sequence_length = int(7*24 / sample_hours)\n",
    "print(\"Sequence Length: %d\" % sequence_length)\n",
    "\n",
    "# Number of features we take from the data\n",
    "input_features = 9\n",
    "num_features = input_features\n",
    "num_inputs = input_features\n",
    "\n",
    "# Number of things we are doing regression to predict\n",
    "num_outputs = 4\n",
    "\n",
    "# Input Features\n",
    "columns = ['hour', 'temp', 'windspd', 'winddir', 'no', 'no2', 'nox', 'o3', 'epoch']\n",
    "\n",
    "# Read the data\n",
    "df = pandas.read_csv('d00.csv')\n",
    "\n",
    "# Drop useless columns\n",
    "df = df.drop(['AQS_Code', 'Latitude', 'Longitude', 'day'], axis=1)\n",
    "\n",
    "# Unprocessed dataset\n",
    "nd = df[columns].values\n",
    "\n",
    "# Windowed dataset\n",
    "nd_window = np.zeros((int(nd.shape[0] / window_stride), num_inputs))\n",
    "\n",
    "row = 0\n",
    "while row < nd.shape[0] - window_stride:\n",
    "    for i in range(0, input_features):\n",
    "        nd_window[int(row/window_stride)][i] = np.mean(nd[row:row+window_stride,i])\n",
    "    row += window_stride\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(nd_window)\n",
    "nd_window = scaler.transform(nd_window)\n",
    "\n",
    "\n",
    "# Create sequences\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "rows = deque(maxlen=sequence_length)\n",
    "\n",
    "for idx, r in enumerate(nd_window):\n",
    "\n",
    "    rows.append([a for a in r])\n",
    "    \n",
    "    # We need the entire sequence filled to make a prediction about the future mean\n",
    "    if len(rows) < sequence_length:\n",
    "        continue\n",
    "    \n",
    "    # Since we are predicting the mean, make sure we do not go out of bounds in the future\n",
    "    if idx+1 + prediction_window > nd_window.shape[0]:\n",
    "        break\n",
    "        \n",
    "    data.append(rows.copy())\n",
    "        \n",
    "    # We are predicting the future mean values\n",
    "    u_24_no = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 4] )\n",
    "    u_24_no2 = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 5] )\n",
    "    u_24_nox = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 6] )\n",
    "    u_24_o3 = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 7] )\n",
    "    \n",
    "    labels.append([u_24_no, u_24_no2, u_24_nox, u_24_o3])\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 168, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 168, 128)          1280      \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 166,916\n",
      "Trainable params: 166,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5455 samples, validate on 2687 samples\n",
      "Epoch 1/100\n",
      "Epoch(1) LR: 0.001000\n",
      "5455/5455 [==============================] - 15s 3ms/step - loss: 0.0451 - r2: 0.5340 - val_loss: 0.0493 - val_r2: 0.7099\n",
      "\n",
      "Epoch 00001: val_r2 improved from -inf to 0.70988, saving model to weights.best.hdf5\n",
      "Epoch 2/100\n",
      "Epoch(2) LR: 0.000950\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0291 - r2: 0.8043 - val_loss: 0.0461 - val_r2: 0.7520\n",
      "\n",
      "Epoch 00002: val_r2 improved from 0.70988 to 0.75197, saving model to weights.best.hdf5\n",
      "Epoch 3/100\n",
      "Epoch(3) LR: 0.000902\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0269 - r2: 0.8280 - val_loss: 0.0485 - val_r2: 0.7209\n",
      "\n",
      "Epoch 00003: val_r2 did not improve from 0.75197\n",
      "Epoch 4/100\n",
      "Epoch(4) LR: 0.000857\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0261 - r2: 0.8388 - val_loss: 0.0510 - val_r2: 0.6997\n",
      "\n",
      "Epoch 00004: val_r2 did not improve from 0.75197\n",
      "Epoch 5/100\n",
      "Epoch(5) LR: 0.000815\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0250 - r2: 0.8474 - val_loss: 0.0492 - val_r2: 0.7213\n",
      "\n",
      "Epoch 00005: val_r2 did not improve from 0.75197\n",
      "Epoch 6/100\n",
      "Epoch(6) LR: 0.000774\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0244 - r2: 0.8526 - val_loss: 0.0494 - val_r2: 0.7178\n",
      "\n",
      "Epoch 00006: val_r2 did not improve from 0.75197\n",
      "Epoch 7/100\n",
      "Epoch(7) LR: 0.000735\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0240 - r2: 0.8586 - val_loss: 0.0486 - val_r2: 0.7322\n",
      "\n",
      "Epoch 00007: val_r2 did not improve from 0.75197\n",
      "Epoch 8/100\n",
      "Epoch(8) LR: 0.000698\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0237 - r2: 0.8626 - val_loss: 0.0484 - val_r2: 0.7288\n",
      "\n",
      "Epoch 00008: val_r2 did not improve from 0.75197\n",
      "Epoch 9/100\n",
      "Epoch(9) LR: 0.000663\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0233 - r2: 0.8653 - val_loss: 0.0512 - val_r2: 0.6858\n",
      "\n",
      "Epoch 00009: val_r2 did not improve from 0.75197\n",
      "Epoch 10/100\n",
      "Epoch(10) LR: 0.000630\n",
      "5455/5455 [==============================] - 12s 2ms/step - loss: 0.0228 - r2: 0.8718 - val_loss: 0.0511 - val_r2: 0.7146\n",
      "\n",
      "Epoch 00010: val_r2 did not improve from 0.75197\n",
      "Epoch 11/100\n",
      "Epoch(11) LR: 0.000599\n",
      "1920/5455 [=========>....................] - ETA: 7s - loss: 0.0224 - r2: 0.8751"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-6593b34159ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, LSTM, Input, Flatten, Concatenate, Conv2D, Conv1D, MaxPooling2D, Reshape, MaxPooling1D\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "layer_input_features = Input(shape=(sequence_length, input_features))\n",
    "\n",
    "# For some reason putting some extra dimensions before an LSTM works wonders\n",
    "layer_x1 = Dense(128, input_dim=(sequence_length, input_features))(layer_input_features)\n",
    "layer_x1 = LSTM(128, return_sequences=False, dropout=0.5)(layer_x1)\n",
    "\n",
    "layer_concat = layer_x1\n",
    "    \n",
    "layer_dense = Dense(256, activation='relu')(layer_concat)\n",
    "layer_output = Dense(num_outputs)(layer_dense)\n",
    "\n",
    "\n",
    "model = Model(inputs=[layer_input_features], outputs=[layer_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=[r2])\n",
    "model.summary()\n",
    "\n",
    "def sched(epoch, lr):\n",
    "    new_lr = 0.001 * (0.95 ** epoch)\n",
    "    print(\"Epoch(%d) LR: %f\" % (epoch+1, new_lr))\n",
    "    return new_lr\n",
    "\n",
    "lr_decay = LearningRateScheduler(schedule=sched) \n",
    "\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_r2', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit(x=data, y=labels, batch_size=128, epochs=100, validation_split=0.33, verbose=True, callbacks=[lr_decay, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendered 0\n",
      "Rendered 1\n",
      "Rendered 2\n",
      "Rendered 3\n",
      "Rendered 4\n",
      "Rendered 5\n",
      "Rendered 6\n",
      "Rendered 7\n",
      "Rendered 8\n",
      "Rendered 9\n",
      "Rendered 10\n",
      "Rendered 11\n",
      "Rendered 12\n",
      "Rendered 13\n",
      "Rendered 14\n",
      "Rendered 15\n",
      "Rendered 16\n",
      "Rendered 17\n",
      "Rendered 18\n",
      "Rendered 19\n",
      "Rendered 20\n",
      "Rendered 21\n",
      "Rendered 22\n",
      "Rendered 23\n",
      "Rendered 24\n",
      "Rendered 25\n",
      "Rendered 26\n",
      "Rendered 27\n",
      "Rendered 28\n",
      "Rendered 29\n",
      "Rendered 30\n",
      "Rendered 31\n",
      "Rendered 32\n",
      "Rendered 33\n",
      "Rendered 34\n",
      "Rendered 35\n",
      "Rendered 36\n",
      "Rendered 37\n",
      "Rendered 38\n",
      "Rendered 39\n",
      "Rendered 40\n",
      "Rendered 41\n",
      "Rendered 42\n",
      "Rendered 43\n",
      "Rendered 44\n",
      "Rendered 45\n",
      "Rendered 46\n",
      "Rendered 47\n",
      "Rendered 48\n",
      "Rendered 49\n",
      "Rendered 50\n",
      "Rendered 51\n",
      "Rendered 52\n",
      "Rendered 53\n",
      "Rendered 54\n",
      "Rendered 55\n",
      "Rendered 56\n",
      "Rendered 57\n",
      "Rendered 58\n",
      "Rendered 59\n",
      "Rendered 60\n",
      "Rendered 61\n",
      "Rendered 62\n",
      "Rendered 63\n",
      "Rendered 64\n",
      "Rendered 65\n",
      "Rendered 66\n",
      "Rendered 67\n",
      "Rendered 68\n",
      "Rendered 69\n",
      "Rendered 70\n",
      "Rendered 71\n",
      "Rendered 72\n",
      "Rendered 73\n",
      "Rendered 74\n",
      "Rendered 75\n",
      "Rendered 76\n",
      "Rendered 77\n",
      "Rendered 78\n",
      "Rendered 79\n",
      "Rendered 80\n",
      "Rendered 81\n",
      "Rendered 82\n",
      "Rendered 83\n",
      "Rendered 84\n",
      "Rendered 85\n",
      "Rendered 86\n",
      "Rendered 87\n",
      "Rendered 88\n",
      "Rendered 89\n",
      "Rendered 90\n",
      "Rendered 91\n",
      "Rendered 92\n",
      "Rendered 93\n",
      "Rendered 94\n",
      "Rendered 95\n",
      "Rendered 96\n",
      "Rendered 97\n",
      "Rendered 98\n",
      "Rendered 99\n",
      "Rendered 100\n",
      "Rendered 101\n",
      "Rendered 102\n",
      "Rendered 103\n",
      "Rendered 104\n",
      "Rendered 105\n",
      "Rendered 106\n",
      "Rendered 107\n",
      "Rendered 108\n",
      "Rendered 109\n",
      "Rendered 110\n",
      "Rendered 111\n",
      "Rendered 112\n",
      "Rendered 113\n",
      "Rendered 114\n",
      "Rendered 115\n",
      "Rendered 116\n",
      "Rendered 117\n",
      "Rendered 118\n",
      "Rendered 119\n",
      "Rendered 120\n",
      "Rendered 121\n",
      "Rendered 122\n",
      "Rendered 123\n",
      "Rendered 124\n",
      "Rendered 125\n",
      "Rendered 126\n",
      "Rendered 127\n",
      "Rendered 128\n",
      "Rendered 129\n",
      "Rendered 130\n",
      "Rendered 131\n",
      "Rendered 132\n",
      "Rendered 133\n",
      "Rendered 134\n",
      "Rendered 135\n",
      "Rendered 136\n",
      "Rendered 137\n",
      "Rendered 138\n",
      "Rendered 139\n",
      "Rendered 140\n",
      "Rendered 141\n",
      "Rendered 142\n",
      "Rendered 143\n",
      "Rendered 144\n",
      "Rendered 145\n",
      "Rendered 146\n",
      "Rendered 147\n",
      "Rendered 148\n",
      "Rendered 149\n",
      "Rendered 150\n",
      "Rendered 151\n",
      "Rendered 152\n",
      "Rendered 153\n",
      "Rendered 154\n",
      "Rendered 155\n",
      "Rendered 156\n",
      "Rendered 157\n",
      "Rendered 158\n",
      "Rendered 159\n",
      "Rendered 160\n",
      "Rendered 161\n",
      "Rendered 162\n",
      "Rendered 163\n",
      "Rendered 164\n",
      "Rendered 165\n",
      "Rendered 166\n",
      "Rendered 167\n",
      "Rendered 168\n",
      "Rendered 169\n",
      "Rendered 170\n",
      "Rendered 171\n",
      "Rendered 172\n",
      "Rendered 173\n",
      "Rendered 174\n",
      "Rendered 175\n",
      "Rendered 176\n",
      "Rendered 177\n",
      "Rendered 178\n",
      "Rendered 179\n",
      "Rendered 180\n",
      "Rendered 181\n",
      "Rendered 182\n",
      "Rendered 183\n",
      "Rendered 184\n",
      "Rendered 185\n",
      "Rendered 186\n",
      "Rendered 187\n",
      "Rendered 188\n",
      "Rendered 189\n",
      "Rendered 190\n",
      "Rendered 191\n",
      "Rendered 192\n",
      "Rendered 193\n",
      "Rendered 194\n",
      "Rendered 195\n",
      "Rendered 196\n",
      "Rendered 197\n",
      "Rendered 198\n",
      "Rendered 199\n",
      "Rendered 200\n",
      "Rendered 201\n",
      "Rendered 202\n",
      "Rendered 203\n",
      "Rendered 204\n",
      "Rendered 205\n",
      "Rendered 206\n",
      "Rendered 207\n",
      "Rendered 208\n",
      "Rendered 209\n",
      "Rendered 210\n",
      "Rendered 211\n",
      "Rendered 212\n",
      "Rendered 213\n",
      "Rendered 214\n",
      "Rendered 215\n",
      "Rendered 216\n",
      "Rendered 217\n",
      "Rendered 218\n",
      "Rendered 219\n",
      "Rendered 220\n",
      "Rendered 221\n",
      "Rendered 222\n",
      "Rendered 223\n",
      "Rendered 224\n",
      "Rendered 225\n",
      "Rendered 226\n",
      "Rendered 227\n",
      "Rendered 228\n",
      "Rendered 229\n",
      "Rendered 230\n",
      "Rendered 231\n",
      "Rendered 232\n",
      "Rendered 233\n",
      "Rendered 234\n",
      "Rendered 235\n",
      "Rendered 236\n",
      "Rendered 237\n",
      "Rendered 238\n",
      "Rendered 239\n",
      "Rendered 240\n",
      "Rendered 241\n",
      "Rendered 242\n",
      "Rendered 243\n",
      "Rendered 244\n",
      "Rendered 245\n",
      "Rendered 246\n",
      "Rendered 247\n",
      "Rendered 248\n",
      "Rendered 249\n",
      "Rendered 250\n",
      "Rendered 251\n",
      "Rendered 252\n",
      "Rendered 253\n",
      "Rendered 254\n",
      "Rendered 255\n",
      "Rendered 256\n",
      "Rendered 257\n",
      "Rendered 258\n",
      "Rendered 259\n",
      "Rendered 260\n",
      "Rendered 261\n",
      "Rendered 262\n",
      "Rendered 263\n",
      "Rendered 264\n",
      "Rendered 265\n",
      "Rendered 266\n",
      "Rendered 267\n",
      "Rendered 268\n",
      "Rendered 269\n",
      "Rendered 270\n",
      "Rendered 271\n",
      "Rendered 272\n",
      "Rendered 273\n",
      "Rendered 274\n",
      "Rendered 275\n",
      "Rendered 276\n",
      "Rendered 277\n",
      "Rendered 278\n",
      "Rendered 279\n",
      "Rendered 280\n",
      "Rendered 281\n",
      "Rendered 282\n",
      "Rendered 283\n",
      "Rendered 284\n",
      "Rendered 285\n",
      "Rendered 286\n",
      "Rendered 287\n",
      "Rendered 288\n",
      "Rendered 289\n",
      "Rendered 290\n",
      "Rendered 291\n",
      "Rendered 292\n",
      "Rendered 293\n",
      "Rendered 294\n",
      "Rendered 295\n",
      "Rendered 296\n",
      "Rendered 297\n",
      "Rendered 298\n",
      "Rendered 299\n",
      "Rendered 300\n",
      "Rendered 301\n",
      "Rendered 302\n",
      "Rendered 303\n",
      "Rendered 304\n",
      "Rendered 305\n",
      "Rendered 306\n",
      "Rendered 307\n",
      "Rendered 308\n",
      "Rendered 309\n",
      "Rendered 310\n",
      "Rendered 311\n",
      "Rendered 312\n",
      "Rendered 313\n",
      "Rendered 314\n",
      "Rendered 315\n",
      "Rendered 316\n",
      "Rendered 317\n",
      "Rendered 318\n",
      "Rendered 319\n",
      "Rendered 320\n",
      "Rendered 321\n",
      "Rendered 322\n",
      "Rendered 323\n",
      "Rendered 324\n",
      "Rendered 325\n",
      "Rendered 326\n",
      "Rendered 327\n",
      "Rendered 328\n",
      "Rendered 329\n",
      "Rendered 330\n",
      "Rendered 331\n",
      "Rendered 332\n",
      "Rendered 333\n",
      "Rendered 334\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights.best.hdf5\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "for seq in range(0, data.shape[0] - sequence_length):\n",
    "    \n",
    "    lookup = {'no': (0, 0), 'no2':(0, 1), 'nox':(1, 0), 'o3':(1, 1)}\n",
    "\n",
    "    pred = model.predict(data[seq].reshape(1, sequence_length, num_features))[0]\n",
    "    fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "    for idx,f in enumerate([(4, 'no'), (5, 'no2'), (6, 'nox'), (7, 'o3')]):\n",
    "    \n",
    "        feature_index, feature_name = f\n",
    "        \n",
    "        X = []\n",
    "        Y_actual = []\n",
    "\n",
    "        for i in range(0, sequence_length + int(24*(1/sample_hours))):\n",
    "            X.append(seq+i)\n",
    "            Y_actual.append(data[seq+i][-1][feature_index])\n",
    "\n",
    "        Y_actual = np.array(Y_actual)\n",
    "        \n",
    "        predicted_mean = pred[feature_index - 4]\n",
    "        actual_mean = np.mean(Y_actual[sequence_length:])\n",
    "        rolling_mean = np.mean(Y_actual[:sequence_length])\n",
    "        rolling_std = np.std(Y_actual[:sequence_length])\n",
    "        \n",
    "        Y_pred = Y_actual.copy()\n",
    "        Y_pred[sequence_length:] = predicted_mean\n",
    "        Y_pred[:sequence_length] = np.nan\n",
    "\n",
    "        Y_actual_mean = Y_actual.copy()\n",
    "        Y_actual_mean[sequence_length:] = actual_mean\n",
    "        Y_actual_mean[:sequence_length] = np.nan\n",
    "        \n",
    "        Y_rolling_mean = Y_actual.copy()\n",
    "        Y_rolling_mean[:sequence_length] = rolling_mean\n",
    "        Y_rolling_mean[sequence_length:] = np.nan\n",
    "        \n",
    "        Y_rolling_std_upper = Y_actual.copy()\n",
    "        Y_rolling_std_upper[:sequence_length] = rolling_mean + rolling_std\n",
    "        Y_rolling_std_upper[sequence_length:] = np.nan\n",
    "        \n",
    "        Y_rolling_std_lower = Y_actual.copy()\n",
    "        Y_rolling_std_lower[:sequence_length] = rolling_mean - rolling_std\n",
    "        Y_rolling_std_lower[sequence_length:] = np.nan   \n",
    "        \n",
    "        subplot = ax[lookup[feature_name][0]][lookup[feature_name][1]]\n",
    "\n",
    "        subplot.plot(X, Y_actual, color='black', linewidth=4.0)\n",
    "        subplot.plot(X, Y_actual_mean, color='green', linewidth=4.0)\n",
    "        subplot.plot(X, Y_pred, color='purple', linewidth=4.0)\n",
    "        subplot.plot(X, Y_rolling_mean, color='green', linewidth=4.0)\n",
    "        subplot.plot(X, Y_rolling_std_upper, color='orange', linewidth=4.0)\n",
    "        subplot.plot(X, Y_rolling_std_lower, color='orange', linewidth=4.0)\n",
    "        \n",
    "\n",
    "        subplot.grid()\n",
    "        \n",
    "        subplot.set_title(\"%s 24 hour mean prediction\" % (feature_name,))\n",
    "        \n",
    "        subplot.set_xlabel(\"Hours\")\n",
    "        subplot.set_ylabel(\"Scaled Concentration\")\n",
    "    \n",
    "    fig.legend(['Actual Continuous', 'Actual Mean', 'Predicted Mean', 'Rolling Mean', 'Standard Deviation'])\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig('charts/%.05d.png' % seq)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Rendered %d\" % seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
