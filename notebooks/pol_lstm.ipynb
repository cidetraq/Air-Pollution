{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Number of future samples to mean for prediction\n",
    "prediction_window = 24\n",
    "\n",
    "# Average window_stride elements together to form a single row\n",
    "window_stride = 12\n",
    "\n",
    "# Length of the windowed sequence\n",
    "sequence_length = 24 * 7\n",
    "\n",
    "# Number of features we take from the data\n",
    "input_features = 8\n",
    "num_inputs = input_features\n",
    "\n",
    "# Number of things we are doing regression to predict\n",
    "num_outputs = 4\n",
    "\n",
    "# Input Features\n",
    "columns = ['hour', 'temp', 'windspd', 'winddir', 'no', 'no2', 'nox', 'o3']\n",
    "\n",
    "# Read the data\n",
    "df = pandas.read_csv('d00_single.csv')\n",
    "\n",
    "# Drop useless columns\n",
    "df = df.drop(['AQS_Code', 'Latitude', 'Longitude', 'epoch', 'day'], axis=1)\n",
    "\n",
    "# Unprocessed dataset\n",
    "nd = df[columns].values\n",
    "\n",
    "# Windowed dataset\n",
    "nd_window = np.zeros((int(nd.shape[0] / window_stride), num_inputs))\n",
    "\n",
    "row = 0\n",
    "while row < nd.shape[0] - window_stride:\n",
    "    for i in range(0, input_features):\n",
    "        nd_window[int(row/window_stride)][i] = np.mean(nd[row:row+window_stride,i])\n",
    "    row += window_stride\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(nd_window)\n",
    "nd_window = scaler.transform(nd_window)\n",
    "\n",
    "\n",
    "# Create sequences\n",
    "data_features = []\n",
    "labels = []\n",
    "\n",
    "rows = deque(maxlen=sequence_length)\n",
    "\n",
    "for idx, r in enumerate(nd_window):\n",
    "\n",
    "    rows.append([a for a in r])\n",
    "    \n",
    "    # We need the entire sequence filled to make a prediction about the future mean\n",
    "    if len(rows) < sequence_length:\n",
    "        continue\n",
    "    \n",
    "    # Since we are predicting the mean, make sure we do not go out of bounds in the future\n",
    "    if idx+1 + prediction_window > nd_window.shape[0]:\n",
    "        break\n",
    "        \n",
    "    data_features.append(rows.copy())\n",
    "        \n",
    "    # We are predicting the future mean values\n",
    "    u_24_no = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 4] )\n",
    "    u_24_no2 = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 5] )\n",
    "    u_24_nox = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 6] )\n",
    "    u_24_o3 = np.mean( nd_window[idx+1 : idx+1 + prediction_window, 7] )\n",
    "    \n",
    "    labels.append([u_24_no, u_24_no2, u_24_nox, u_24_o3])\n",
    "\n",
    "data_features = np.array(data_features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, LSTM, Input, Flatten, Concatenate, Conv2D, Conv1D, MaxPooling2D, Reshape, MaxPooling1D\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "layer_input_features = Input(shape=(sequence_length, input_features))\n",
    "\n",
    "# For some reason putting some extra dimensions before an LSTM works wonders\n",
    "layer_x1 = Dense(128, input_dim=(sequence_length, input_features))(layer_input_features)\n",
    "layer_x1 = LSTM(256, return_sequences=True, dropout=0.5)(layer_x1)\n",
    "layer_x1 = LSTM(256, return_sequences=False, dropout=0.5)(layer_x1)\n",
    "\n",
    "layer_concat = layer_x1\n",
    "    \n",
    "layer_dense = Dense(512, activation='relu')(layer_concat)\n",
    "layer_output = Dense(num_outputs)(layer_dense)\n",
    "\n",
    "\n",
    "model = Model(inputs=[layer_input_features], outputs=[layer_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2])\n",
    "model.summary()\n",
    "\n",
    "def sched(epoch, lr):\n",
    "    new_lr = 0.001 * (0.95 ** epoch)\n",
    "    print(\"Epoch(%d) LR: %f\" % (epoch+1, new_lr))\n",
    "    return new_lr\n",
    "\n",
    "lr_decay = LearningRateScheduler(schedule=sched) \n",
    "\n",
    "model.fit(x=data_features, y=labels, batch_size=128, epochs=100, validation_split=0.33, verbose=True, callbacks=[lr_decay])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
