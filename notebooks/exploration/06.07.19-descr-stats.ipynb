{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply the datetime operations\n",
    "\n",
    "Stats: Range, median, average, Q1, Q3, histograms, density plot, percent missing data, total size of dataset\n",
    "\n",
    "(For each year 2000-2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_xlim(series):\n",
    "    if is_numeric_dtype(series):\n",
    "        return series.median()+3*series.std() \n",
    "    else:\n",
    "        return max(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_higho3_days(df):\n",
    "    high_fiveminutes = df[df['o3'] > 40]\n",
    "    fiveminutes_daymonths = high_fiveminutes[['day', 'month']]\n",
    "    high_o3_index = df[['day', 'month']].isin(fiveminutes_daymonths)\n",
    "    high_o3_days = df.iloc[high_o3[high_o3['day'] == True].index]\n",
    "    return high_o3_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(df_dict, year, output_path):\n",
    "    year = str(year)\n",
    "    for df_name in df_dict: \n",
    "        df = df_dict[df_name]\n",
    "        descr_stats = df.describe(include='all')\n",
    "        #documentation here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html\n",
    "        #descr_stats.to_csv('output_path+output_name')\n",
    "        #descr_stats.to_csv('D:/programming-no-gdrive/DASH/Air Pollution/descriptive-output/data00_descr_stats.csv')\n",
    "        descr_stats.to_csv(output_path+year+'-'+df_name+'-'+'descr_stats.csv')\n",
    "        hists = df.hist(figsize=(72,72))\n",
    "        #default is 10 bins for each plot\n",
    "        #plt.savefig(\"D:/programming-no-gdrive/DASH/Air Pollution/descriptive-output/data00_hist.png\")\n",
    "        plt.savefig(output_path+year+'-'+df_name+'-'+\"hist.png\")\n",
    "        #densities = df.plot.density(figsize=(72,72))\n",
    "        #plt.savefig(\"D:/programming-no-gdrive/DASH/Air Pollution/descriptive-output/data00_density.png\")\n",
    "        #To get amount of missing values in each column (do for each df)\n",
    "        percent_missing = df.isna().mean().round(4) * 100\n",
    "        percent_missing.to_csv(output_path+year+'-'+df_name+'-'+\"percent_missing.csv\")\n",
    "        #size of dataset\n",
    "        with open(output_path+df_name, \"a\") as file:\n",
    "            file.write((\"Number of rows in dataset \"+df_name+\"-\"year+\":\"+str(len(df))))\n",
    "        cleaned = df.dropna(axis = 1, how='all').select_dtypes(['number'])\n",
    "        for col in cleaned:\n",
    "            fig, ax = plt.subplots()\n",
    "            try:\n",
    "                cleaned[col].plot.kde(ax=ax, legend=False, title=col)\n",
    "            except BaseException:\n",
    "                pass\n",
    "            cleaned[col].plot.hist(density=True, ax=ax)\n",
    "            plt.xlim(left = 0, right =find_xlim(cleaned[col]))\n",
    "            plt.savefig(output_path+year+'-'+df_name+'-'+col+\"-density.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plac.annotations(\n",
    "    input_path=(\"Path containing the data files to ingest\", \"option\", \"p\", str),\n",
    "    input_prefix=(\"{$prefix}year.csv\", \"option\", \"P\", str),\n",
    "    input_suffix=(\"year{$suffix}.csv\", \"option\", \"S\", str),\n",
    "    output_path=(\"Path to write the resulting numpy sequences / transform cache\", \"option\", \"o\", str),\n",
    "    year_begin=(\"First year to process\", \"option\", \"b\", int),\n",
    "    year_end=(\"Year to stop with\", \"option\", \"e\", int),\n",
    "    aqsnumerical=(\"Convert AQS code to numerical\", \"flag\", \"A\"),\n",
    "    houston=(\"Only run for Houston sites\", \"flag\", \"H\"),\n",
    "    chunksize=(\"Process this many records at one time\", \"option\", 'C', int)\n",
    ")\n",
    "def main(input_path: str = '/project/lindner/air-pollution/level3_data/',\n",
    "         input_prefix: str = \"Data_\",\n",
    "         input_suffix: str = \"\",\n",
    "         output_path: str = '/project/lindner/air-pollution/current/2019/descriptive-output/',\n",
    "         year_begin: int = 2000,\n",
    "         year_end: int = 2018,\n",
    "         aqsnumerical: bool = False,\n",
    "         houston: bool = False,\n",
    "         chunksize: int = 200000):\n",
    "    \n",
    "    all_years = []\n",
    "    #for now just one file, later all years\n",
    "    for year in range(year_begin,year_end):\n",
    "        all_years.append(pd.read_csv(input_path+input_prefix+str(year)+\".csv\"))\n",
    "    for index, df in enumerate(all_years):\n",
    "        #Time series\n",
    "        df['hour'] = pd.to_datetime(df['epoch'], unit='s').dt.hour\n",
    "        df['day'] = pd.to_datetime(df['epoch'], unit='s').dt.day\n",
    "        df['month'] = pd.to_datetime(df['epoch'], unit='s').dt.month\n",
    "        daytime = df[(df['hour'] > 6) & (df['hour'] < 20)]\n",
    "        nighttime = df[(df['hour'] < 7) | (df['hour'] > 20)]\n",
    "        highpol_months = df[(df['month'] >3) & (df['month'] < 11)]\n",
    "        higho3_days = get_higho3_days(df)\n",
    "        subsets = {\"df\":df, \"daytime\":daytime, \"nighttime\":nighttime, \"highpol_months\":highpol_months, \"higho3_days\":higho3_days}\n",
    "        analyze(subsets, index, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Site-wise analysis</h2>\n",
    "\n",
    "To get site-wise analysis, run the same code on each generated site data file (each will contain all years). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfdfd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-3e964b5cd78a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#drop all sites other than the one requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AQS_Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdfdfd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfdfd' is not defined"
     ]
    }
   ],
   "source": [
    "def transform(df: pd.DataFrame, year: int, fillgps: bool = False, naninvalid: bool = False, dropnan: bool = False, masknan: float = None, fillnan: float = None, aqsnumerical: bool = False, sites = []) -> pd.DataFrame:\n",
    "\n",
    "    if len(sites) > 0:\n",
    "        #drop all sites other than the one requested\n",
    "        df.drop(df[~df['AQS_Code'].isin(sites)].index, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
