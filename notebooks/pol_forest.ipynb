{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Hours: 1.000000\n",
      "Prediction Window: 24\n",
      "Sequence Length: 168\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Average window_stride elements together to form a single row\n",
    "window_stride = 12\n",
    "\n",
    "sample_hours = window_stride / 12.0\n",
    "print(\"Sample Hours: %f\" % sample_hours)\n",
    "\n",
    "# Number of future samples to mean for prediction\n",
    "prediction_window = int(24 / sample_hours)\n",
    "print(\"Prediction Window: %d\" % prediction_window)\n",
    "\n",
    "# Length of the windowed sequence\n",
    "sequence_length = int(7*24 / sample_hours)\n",
    "print(\"Sequence Length: %d\" % sequence_length)\n",
    "\n",
    "# Input Features\n",
    "input_columns = ['epoch', 'hour', 'temp', 'windspd', 'winddir', 'no', 'no2', 'nox', 'o3']\n",
    "output_columns = ['no', 'no2', 'nox', 'o3']\n",
    "\n",
    "# Take the FFT of each sqeuence and use as features\n",
    "fft_features = False\n",
    "\n",
    "# Fit the sequence to y = mx+b and add the coeff / intercept\n",
    "regression_features = True\n",
    "\n",
    "# Add variance for each feature in the sequence\n",
    "std_features = True\n",
    "\n",
    "input_map = {value: idx for idx, value in enumerate(input_columns)}\n",
    "output_map = {value: idx for idx, value in enumerate(output_columns)}\n",
    "\n",
    "# Number of features we take from the data\n",
    "num_inputs = len(input_columns)\n",
    "\n",
    "# Number of things we are doing regression to predict\n",
    "num_outputs = len(output_columns)\n",
    "\n",
    "# All the timesteps features unrolled length\n",
    "unrolled_input_length = num_inputs * sequence_length\n",
    "\n",
    "train_validation_split = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--data--\n",
      "(8142, 1362)\n",
      "--labels--\n",
      "(8142, 4)\n"
     ]
    }
   ],
   "source": [
    "# ----- Feature Extraction ------\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Read the data\n",
    "df = pandas.read_csv('d00.csv')\n",
    "\n",
    "# Drop useless columns\n",
    "df = df.drop(['AQS_Code', 'Latitude', 'Longitude', 'day'], axis=1)\n",
    "\n",
    "# Move from pandas to numpy for windowing\n",
    "nd = df[input_columns].values\n",
    "\n",
    "# Windowed dataset\n",
    "nd_window = np.zeros((int(nd.shape[0] / window_stride), num_inputs))\n",
    "\n",
    "row = 0\n",
    "while row < nd.shape[0] - window_stride:\n",
    "    for i in range(0, num_inputs):\n",
    "        nd_window[int(row/window_stride)][i] = np.mean(nd[row:row+window_stride,i])\n",
    "    row += window_stride\n",
    "    \n",
    "# Scale the values between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(nd_window)\n",
    "nd_window = scaler.transform(nd_window)\n",
    "\n",
    "# Create sequences for training\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "rows = deque(maxlen=sequence_length)\n",
    "\n",
    "for idx, r in enumerate(nd_window):\n",
    "\n",
    "    rows.append([f for f in r])\n",
    "    \n",
    "    # We need the entire sequence filled to make a prediction about the future mean\n",
    "    if len(rows) < sequence_length:\n",
    "        continue\n",
    "    \n",
    "    # Since we are predicting the mean, make sure we do not go out of bounds in the future\n",
    "    if idx+1 + prediction_window > nd_window.shape[0]:\n",
    "        break\n",
    "                \n",
    "    data.append(list(rows).copy())\n",
    "        \n",
    "    # We are predicting the future mean values\n",
    "    u_24_no = np.mean( nd_window[idx+1 : idx+1 + prediction_window, input_map['no']] )\n",
    "    u_24_no2 = np.mean( nd_window[idx+1 : idx+1 + prediction_window, input_map['no2']] )\n",
    "    u_24_nox = np.mean( nd_window[idx+1 : idx+1 + prediction_window, input_map['nox']] )\n",
    "    u_24_o3 = np.mean( nd_window[idx+1 : idx+1 + prediction_window, input_map['o3']] )\n",
    "    \n",
    "    labels.append([u_24_no, u_24_no2, u_24_nox, u_24_o3])\n",
    "\n",
    "# Add some features\n",
    "for idx, r in enumerate(data):\n",
    "    \n",
    "    features_to_add = []\n",
    "        \n",
    "    if fft_features:\n",
    "                \n",
    "        bins = np.abs(np.fft.fft(r))\n",
    "        bins = bins[:int(len(bins)/2)]\n",
    "\n",
    "        fft_features = len(bins)\n",
    "\n",
    "        features_to_add.extend(np.array(bins[:, 2:8]).ravel().tolist())\n",
    "        \n",
    "        new_r.extend(features_to_add)\n",
    "        \n",
    "    if regression_features:\n",
    "        for f in range(2, num_inputs):\n",
    "\n",
    "            X = [[i] for i in range(0, sequence_length)]\n",
    "            Y = [[i] for i in np.array(r)[:, f].tolist()]\n",
    "            \n",
    "            lr = LinearRegression().fit(X, Y)\n",
    "            \n",
    "            features_to_add.extend([lr.coef_[0][0], lr.intercept_[0]])\n",
    "            \n",
    "    if std_features:\n",
    "        for f in range(2, num_inputs):\n",
    "            features_to_add.append(np.std(np.array(r)[:, f]))\n",
    "\n",
    "    new_r = np.array(r).ravel().tolist()\n",
    "    new_r.extend(features_to_add)\n",
    "    \n",
    "    data[idx] = new_r\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"--data--\")\n",
    "print(data.shape)\n",
    "print(\"--labels--\")\n",
    "print(labels.shape)\n",
    "\n",
    "# Train validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(1) - R^2: 0.885263\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "best_r2 = None\n",
    "\n",
    "for epoch in range(0, 100):\n",
    "    regr = RandomForestRegressor(random_state=epoch, n_estimators=100, n_jobs=-1, verbose=0)\n",
    "    regr.fit(X_train, y_train)\n",
    "    r2 = regr.score(X_test, y_test)\n",
    "    \n",
    "    save = False\n",
    "    \n",
    "    if best_r2 is None:\n",
    "        print(\"epoch(%d) - R^2: %f\" % (epoch+1, r2))\n",
    "        best_r2 = r2\n",
    "        save = True\n",
    "    elif r2 > best_r2:\n",
    "        print(\"epoch(%d) - R^2 improved: %f (best: %f)\" % (epoch+1, r2, best_r2))\n",
    "        best_r2 = r2\n",
    "        save = True\n",
    "    else:\n",
    "        print(\"epoch(%d) - R^2 did not improve: %f (best: %f)\" % (epoch+1, r2, best_r2))\n",
    "    \n",
    "    if save:\n",
    "        open('random-forest.best.pickle', 'wb').write(pickle.dumps(regr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT Visualization\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "bins = np.abs(np.fft.fft(data[400][:unrolled_input_length].reshape((sequence_length, num_inputs))))\n",
    "freqs = np.fft.fftfreq(len(bins), d=300*12)[:int(len(bins)/2)]\n",
    "bins = bins[:int(len(bins)/2)]\n",
    "\n",
    "for key in output_map:\n",
    "    plt.plot(freqs, bins[:,output_map[key]])\n",
    "    \n",
    "plt.legend([output_columns[idx] for idx in range(0, num_outputs)])\n",
    "plt.title(\"Windowed Data FFT\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitude (Scaled)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-33858ea09015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'no'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'no2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nox'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o3'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munrolled_input_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfft_features\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[1;32m    355\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before exploiting the model."
     ]
    }
   ],
   "source": [
    "# Visual Simulation\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "for seq in range(0, data.shape[0] - sequence_length):\n",
    "    \n",
    "    lookup = {'no': (0, 0), 'no2':(0, 1), 'nox':(1, 0), 'o3':(1, 1)}\n",
    "\n",
    "    pred = regr.predict(data[seq].reshape((1, unrolled_input_length + fft_features*4)))[0]\n",
    "    fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "    for idx, f in enumerate([(5, 'no'), (6, 'no2'), (7, 'nox'), (8, 'o3')]):\n",
    "    \n",
    "        feature_index, feature_name = f\n",
    "        \n",
    "        X = []\n",
    "        Y_actual = []\n",
    "\n",
    "        for i in range(0, sequence_length + int(24*(1/sample_hours))):\n",
    "            X.append(seq+i)\n",
    "            Y_actual.append(data[seq+i][feature_index])\n",
    "\n",
    "        Y_actual = np.array(Y_actual)\n",
    "        \n",
    "        predicted_mean = pred[feature_index - 5]\n",
    "        actual_mean = np.mean(Y_actual[sequence_length:])\n",
    "        rolling_mean = np.mean(Y_actual[:sequence_length])\n",
    "        rolling_std = np.std(Y_actual[:sequence_length])\n",
    "                \n",
    "        Y_pred = Y_actual.copy()\n",
    "        Y_pred[sequence_length:] = predicted_mean\n",
    "        Y_pred[:sequence_length] = np.nan\n",
    "\n",
    "        Y_actual_mean = Y_actual.copy()\n",
    "        Y_actual_mean[sequence_length:] = actual_mean\n",
    "        Y_actual_mean[:sequence_length] = np.nan\n",
    "        \n",
    "        Y_rolling_mean = Y_actual.copy()\n",
    "        Y_rolling_mean[:sequence_length] = rolling_mean\n",
    "        Y_rolling_mean[sequence_length:] = np.nan\n",
    "        \n",
    "        Y_rolling_std_upper = Y_actual.copy()\n",
    "        Y_rolling_std_upper[:sequence_length] = rolling_mean + rolling_std\n",
    "        Y_rolling_std_upper[sequence_length:] = np.nan\n",
    "        \n",
    "        Y_rolling_std_lower = Y_actual.copy()\n",
    "        Y_rolling_std_lower[:sequence_length] = rolling_mean - rolling_std\n",
    "        Y_rolling_std_lower[sequence_length:] = np.nan   \n",
    "        \n",
    "        subplot = ax[lookup[feature_name][0]][lookup[feature_name][1]]\n",
    "\n",
    "        subplot.plot(X, Y_actual, color='black', linewidth=4.0)\n",
    "        subplot.plot(X, Y_actual_mean, color='green', linewidth=4.0)\n",
    "        subplot.plot(X, Y_pred, color='purple', linewidth=4.0)\n",
    "        subplot.plot(X, Y_rolling_mean, color='green', linewidth=4.0)\n",
    "        subplot.plot(X, Y_rolling_std_upper, color='orange', linewidth=4.0)\n",
    "        subplot.plot(X, Y_rolling_std_lower, color='orange', linewidth=4.0)\n",
    "        \n",
    "        subplot.grid()\n",
    "        \n",
    "        subplot.set_title(\"%s 24 hour mean prediction\" % (feature_name,))\n",
    "        \n",
    "        subplot.set_xlabel(\"Hours\")\n",
    "        subplot.set_ylabel(\"Scaled Concentration\")\n",
    "    \n",
    "    fig.legend(['Actual Continuous', 'Actual Mean', 'Predicted Mean', 'Rolling Mean', 'Standard Deviation'])\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig('charts/%.05d.png' % seq)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    if seq % 100 == 0:\n",
    "        print(\"Rendered %d\" % seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
