{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles={'cluster': \n",
    "          {'in_path': '/project/lindner/moving/summer2018/2019/data-intermediate/', \n",
    "           'out_path':'/project/lindner/moving/summer2018/2019/data-intermediate/new-seqs/'},\n",
    "          'nicholas': {'in_path':'D:/programming-no-gdrive/air-pollution/data-intermediate/',\n",
    "                       'out_path':'D:/programming-no-gdrive/air-pollution/data-intermediate/new_seqs/'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-u\", '--user', type=str,\n",
    "                    help=\"cluster, nicholas, carroll\")\n",
    "args = parser.parse_args()\n",
    "import os\n",
    "args.user='cluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.user=='nicholas':\n",
    "    os.chdir('../parallel/')\n",
    "    os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.user=='cluster':\n",
    "    #from processor_pipeline_nicholas import SequenceFeatureEnricher\n",
    "    from processor_pipeline_nicholas import SequenceBuilder\n",
    "    import d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceFeatureEnricher(object):\n",
    "    def __init__(self, regression_features=True, std_features=True, kmeans_features=True, masknan: float = None, n_clusters=8):\n",
    "        self.regression_features = regression_features\n",
    "        self.std_features = std_features\n",
    "        self.kmeans_features= kmeans_features\n",
    "        self.n_clusters=n_clusters\n",
    "        self.masknan = masknan\n",
    "        self.sample_sequences = []\n",
    "        self.sequence_features = []\n",
    "        # So we can map sequence features back to minmax values for scaling\n",
    "        self.sequence_features_scalar_map = []\n",
    "        if regression_features:\n",
    "            for f in range(d.ENRICH_START, d.NUM_INPUTS):\n",
    "                self.sequence_features_scalar_map.append(f)\n",
    "                self.sequence_features_scalar_map.append(f)\n",
    "        if std_features:\n",
    "            for f in range(d.ENRICH_START, d.NUM_INPUTS):\n",
    "                self.sequence_features_scalar_map.append(f)    \n",
    "    def kmeans_process(self, nd: np.ndarray):\n",
    "        from sklearn.cluster import KMeans\n",
    "        print(str(self.n_clusters)+' clusters in K Means:')\n",
    "        kmeans=KMeans(n_clusters=self.n_clusters, n_jobs=-1, verbose=1, max_iter=50).fit(nd)\n",
    "        return kmeans.labels_, kmeans.cluster_centers_, kmeans.inertia_\n",
    "    def process(self, nd: np.ndarray):\n",
    "        # Add some features\n",
    "        for sequence in range(0, nd.shape[0]):\n",
    "            features_to_add = []\n",
    "            if self.regression_features:\n",
    "                for f in range(d.ENRICH_START, d.NUM_INPUTS):\n",
    "                    m = np.nansum(nd[sequence][:, f]) / np.nansum(np.arange(0, nd.shape[1]))\n",
    "                    b = nd[sequence][:, f][0]\n",
    "\n",
    "                    features_to_add.extend([m, b])\n",
    "            if self.std_features:\n",
    "                for f in range(d.ENRICH_START, d.NUM_INPUTS):\n",
    "                    features_to_add.append(np.nanstd(nd[sequence][:, f]))\n",
    "            self.sample_sequences.append(nd[sequence])\n",
    "            self.sequence_features.append(features_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path=profiles[args.user]['in_path']\n",
    "out_path=profiles[args.user]['out_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd=np.load(open(in_path+'windowed_2000.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "nd=scaler.fit_transform(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder=SequenceBuilder(sequence_length=d.SEQUENCE_LENGTH, prediction_window=d.PREDICTION_WINDOW, prediction_names=d.OUTPUT_COLUMNS)\n",
    "sequences=builder.process(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "data_sequences=sequences\n",
    "data_sequences = data_sequences.reshape(data_sequences.shape[0], data_sequences.shape[1]*data_sequences.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For all at once\n",
    "labels_all=[]\n",
    "cluster_centers_all=[]\n",
    "inertias=[]\n",
    "cluster_sizes=[]\n",
    "for n_clusters in range(4,20,2):\n",
    "    enricher=SequenceFeatureEnricher(n_clusters=n_clusters)\n",
    "    labels, cluster_centers,inertia=enricher.kmeans_process(data_sequences)\n",
    "    labels_all.append(labels)\n",
    "    cluster_centers_all.append(cluster_centers)\n",
    "    inertias.append(inertia)\n",
    "    cluster_sizes.append(n_clusters)\n",
    "    print(str(n_clusters)+' clusters')\n",
    "labels_all=np.array(labels_all)\n",
    "cluster_centers_all=np.array(cluster_centers_all)\n",
    "inertias=np.array(inertias)\n",
    "pickle.dump(labels_all, open(out_path+'labels_all_2000.ndarray', 'wb'), protocol=4)\n",
    "pickle.dump(cluster_centers_all, open(out_path+'cluster_centers_all_2000.ndarray', 'wb'), protocol=4)\n",
    "pickle.dump(inertias, open(out_path+'inertias_all_2000.ndarray', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For individually\n",
    "#For all at once\n",
    "labels_all=[]\n",
    "cluster_centers_all=[]\n",
    "inertias=[]\n",
    "cluster_sizes=[]\n",
    "for n_clusters in range(4,20,2):\n",
    "    print(str(n_clusters)+' clusters')\n",
    "    enricher=SequenceFeatureEnricher(n_clusters=n_clusters)\n",
    "    labels, cluster_centers,inertia=enricher.kmeans_process(data_sequences)\n",
    "    pickle.dump(labels, open(out_path+'labels_2000_'+str(n_clusters)+'clusters.ndarray', 'wb'), protocol=4)\n",
    "    pickle.dump(cluster_centers, open(out_path+'cluster_centers_2000_'+str(n_clusters)+'clusters.ndarray', 'wb'), protocol=4)\n",
    "    pickle.dump(inertia, open(out_path+'inertia_2000_'+str(n_clusters)+'clusters.ndarray', 'wb'), protocol=4)\n",
    "    inertias.append(inertia)\n",
    "    cluster_sizes.append(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cluster_sizes, inertias, 'go')\n",
    "plt.xlabel('Cluster sizes')\n",
    "plt.ylabel('Distances to center of clusters')\n",
    "plt.title('Plot of K Means k values')\n",
    "plt.savefig(out_path+'kmeans_plot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
