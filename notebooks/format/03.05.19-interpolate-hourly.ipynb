{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous without latlong\n",
    "#data=pd.read_csv(\"D:/programming-no-gdrive/air-pollution/data-formatted/03.03.19-restrict-hours/all_sites-2000.csv\")\n",
    "#Current\n",
    "data=pd.read_csv(\"D:/programming-no-gdrive/air-pollution/data-formatted/03.03.19-restrict-hours/all_sites-2000-wlatlong.csv\")\n",
    "data = data.drop(['AQS_Code'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has no nulls in it. Currently testing on just 2000 data. My idea is that we should do one interpolation with 2000 and one with 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0    19144\n",
       "10.0    18933\n",
       "8.0     18694\n",
       "11.0    18097\n",
       "9.0     17813\n",
       "7.0     17096\n",
       "3.0     16353\n",
       "5.0     16257\n",
       "4.0     15996\n",
       "6.0     15832\n",
       "2.0     14833\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time I made a note that January had far less data than other months so I would drop it. Here it is already not represented at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(data.drop(['o3'],axis = 1) , data[['o3']], random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalize below for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Convert Y to np arrays for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Try normalization on Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>First Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04433974365258364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train,y_train)\n",
    "print(reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest</h2>\n",
    "\n",
    "First try without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicholas\\Anaconda3\\envs\\deep-learning\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 0, verbose = 1)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42803537086281207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Below is older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicholas\\Anaconda3\\envs\\deep-learning\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf1000 = RandomForestRegressor(n_estimators = 1000, random_state = 0, verbose = 1)\n",
    "# Train the model on training data\n",
    "rf1000.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47667216690489556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   20.9s finished\n"
     ]
    }
   ],
   "source": [
    "print(rf1000.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hrly_rf_10.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib_file = \"hrly_rf_10.pkl\"  \n",
    "joblib.dump(rf, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_absolute_error', optimizer ='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0271 - mean_absolute_error: 0.0271\n",
      "Epoch 2/50\n",
      "141786/141786 [==============================] - 3s 18us/step - loss: 0.0194 - mean_absolute_error: 0.0194\n",
      "Epoch 3/50\n",
      "141786/141786 [==============================] - 3s 18us/step - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 4/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0186 - mean_absolute_error: 0.0186\n",
      "Epoch 5/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 6/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0183 - mean_absolute_error: 0.0183\n",
      "Epoch 7/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 8/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 9/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0178 - mean_absolute_error: 0.0178\n",
      "Epoch 10/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0178 - mean_absolute_error: 0.0178\n",
      "Epoch 11/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0177 - mean_absolute_error: 0.0177\n",
      "Epoch 12/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0176 - mean_absolute_error: 0.0176\n",
      "Epoch 13/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0175 - mean_absolute_error: 0.0175\n",
      "Epoch 14/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0174 - mean_absolute_error: 0.0174\n",
      "Epoch 15/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0174 - mean_absolute_error: 0.0174\n",
      "Epoch 16/50\n",
      "141786/141786 [==============================] - 4s 28us/step - loss: 0.0173 - mean_absolute_error: 0.0173\n",
      "Epoch 17/50\n",
      "141786/141786 [==============================] - 4s 27us/step - loss: 0.0171 - mean_absolute_error: 0.0171\n",
      "Epoch 18/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0169 - mean_absolute_error: 0.0169\n",
      "Epoch 19/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0168 - mean_absolute_error: 0.0168\n",
      "Epoch 20/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0167 - mean_absolute_error: 0.0167\n",
      "Epoch 21/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0166 - mean_absolute_error: 0.0166\n",
      "Epoch 22/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0166 - mean_absolute_error: 0.0166\n",
      "Epoch 23/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0165 - mean_absolute_error: 0.0165\n",
      "Epoch 24/50\n",
      "141786/141786 [==============================] - 5s 35us/step - loss: 0.0165 - mean_absolute_error: 0.0165\n",
      "Epoch 25/50\n",
      "141786/141786 [==============================] - 4s 27us/step - loss: 0.0165 - mean_absolute_error: 0.0165\n",
      "Epoch 26/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 27/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 28/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 29/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 30/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 31/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 32/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 33/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 34/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 35/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 36/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 37/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 38/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 39/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 40/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 41/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 42/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 43/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 44/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 45/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 46/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 47/50\n",
      "141786/141786 [==============================] - ETA: 0s - loss: 0.0163 - mean_absolute_error: 0.016 - 3s 21us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 48/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0162 - mean_absolute_error: 0.0162\n",
      "Epoch 49/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 50/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0162 - mean_absolute_error: 0.0162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1296d8d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=50, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47262/47262 [==============================] - 1s 15us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.030036334211324334, 0.030036334211324334]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"D:/programming-no-gdrive/air-pollution/models/hrly_2000_ann.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ANN Modeled after Carroll's LSTM's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2, 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0026 - r2: -0.3229 - mean_absolute_error: 0.0263\n",
      "Epoch 2/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0022 - r2: 0.0804 - mean_absolute_error: 0.0220\n",
      "Epoch 3/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0021 - r2: 0.1127 - mean_absolute_error: 0.0213\n",
      "Epoch 4/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0021 - r2: 0.1353 - mean_absolute_error: 0.0210\n",
      "Epoch 5/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0021 - r2: 0.1396 - mean_absolute_error: 0.0209\n",
      "Epoch 6/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0021 - r2: 0.1406 - mean_absolute_error: 0.0208\n",
      "Epoch 7/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0020 - r2: 0.1369 - mean_absolute_error: 0.0208\n",
      "Epoch 8/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0020 - r2: 0.1398 - mean_absolute_error: 0.0207\n",
      "Epoch 9/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0020 - r2: 0.1396 - mean_absolute_error: 0.0207\n",
      "Epoch 10/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0020 - r2: 0.1317 - mean_absolute_error: 0.0206\n",
      "Epoch 11/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0020 - r2: 0.1264 - mean_absolute_error: 0.0206\n",
      "Epoch 12/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0020 - r2: 0.1391 - mean_absolute_error: 0.0206\n",
      "Epoch 13/50\n",
      "141786/141786 [==============================] - 3s 20us/step - loss: 0.0019 - r2: 0.1220 - mean_absolute_error: 0.0205\n",
      "Epoch 14/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0019 - r2: 0.1248 - mean_absolute_error: 0.0205\n",
      "Epoch 15/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0019 - r2: 0.1421 - mean_absolute_error: 0.0204\n",
      "Epoch 16/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0019 - r2: 0.1298 - mean_absolute_error: 0.0204\n",
      "Epoch 17/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0019 - r2: 0.1259 - mean_absolute_error: 0.0204\n",
      "Epoch 18/50\n",
      "141786/141786 [==============================] - 3s 19us/step - loss: 0.0019 - r2: 0.1331 - mean_absolute_error: 0.0205\n",
      "Epoch 19/50\n",
      "141786/141786 [==============================] - 3s 18us/step - loss: 0.0019 - r2: 0.1419 - mean_absolute_error: 0.0204\n",
      "Epoch 20/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0018 - r2: 0.1251 - mean_absolute_error: 0.0204\n",
      "Epoch 21/50\n",
      "141786/141786 [==============================] - 3s 25us/step - loss: 0.0019 - r2: 0.1334 - mean_absolute_error: 0.0205\n",
      "Epoch 22/50\n",
      "141786/141786 [==============================] - 3s 24us/step - loss: 0.0018 - r2: 0.1486 - mean_absolute_error: 0.0205\n",
      "Epoch 23/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0018 - r2: 0.1333 - mean_absolute_error: 0.0205\n",
      "Epoch 24/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0017 - r2: 0.1480 - mean_absolute_error: 0.0204\n",
      "Epoch 25/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0018 - r2: 0.1566 - mean_absolute_error: 0.0205\n",
      "Epoch 26/50\n",
      "141786/141786 [==============================] - 3s 24us/step - loss: 0.0018 - r2: 0.1371 - mean_absolute_error: 0.0206\n",
      "Epoch 27/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0017 - r2: 0.1548 - mean_absolute_error: 0.0204\n",
      "Epoch 28/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0017 - r2: 0.1347 - mean_absolute_error: 0.0205\n",
      "Epoch 29/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0017 - r2: 0.1385 - mean_absolute_error: 0.0206\n",
      "Epoch 30/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0017 - r2: 0.1455 - mean_absolute_error: 0.0205\n",
      "Epoch 31/50\n",
      "141786/141786 [==============================] - 4s 27us/step - loss: 0.0017 - r2: 0.1577 - mean_absolute_error: 0.0205 0s - loss: 0.0017 - r2: 0.\n",
      "Epoch 32/50\n",
      "141786/141786 [==============================] - 4s 25us/step - loss: 0.0017 - r2: 0.1613 - mean_absolute_error: 0.0205\n",
      "Epoch 33/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0017 - r2: 0.1443 - mean_absolute_error: 0.0204\n",
      "Epoch 34/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0017 - r2: 0.1639 - mean_absolute_error: 0.0204\n",
      "Epoch 35/50\n",
      "141786/141786 [==============================] - 4s 25us/step - loss: 0.0016 - r2: 0.1629 - mean_absolute_error: 0.0204\n",
      "Epoch 36/50\n",
      "141786/141786 [==============================] - 3s 24us/step - loss: 0.0017 - r2: 0.1429 - mean_absolute_error: 0.0204\n",
      "Epoch 37/50\n",
      "141786/141786 [==============================] - 4s 26us/step - loss: 0.0016 - r2: 0.1503 - mean_absolute_error: 0.0204\n",
      "Epoch 38/50\n",
      "141786/141786 [==============================] - 3s 24us/step - loss: 0.0017 - r2: 0.1688 - mean_absolute_error: 0.0204\n",
      "Epoch 39/50\n",
      "141786/141786 [==============================] - 3s 23us/step - loss: 0.0017 - r2: 0.1471 - mean_absolute_error: 0.0204\n",
      "Epoch 40/50\n",
      "141786/141786 [==============================] - 4s 27us/step - loss: 0.0016 - r2: 0.1494 - mean_absolute_error: 0.0204\n",
      "Epoch 41/50\n",
      "141786/141786 [==============================] - 3s 24us/step - loss: 0.0016 - r2: 0.1559 - mean_absolute_error: 0.0203\n",
      "Epoch 42/50\n",
      "141786/141786 [==============================] - 4s 29us/step - loss: 0.0016 - r2: 0.1618 - mean_absolute_error: 0.0203\n",
      "Epoch 43/50\n",
      "141786/141786 [==============================] - 3s 25us/step - loss: 0.0016 - r2: 0.1553 - mean_absolute_error: 0.0203\n",
      "Epoch 44/50\n",
      "141786/141786 [==============================] - 3s 24us/step - loss: 0.0016 - r2: 0.1751 - mean_absolute_error: 0.0202\n",
      "Epoch 45/50\n",
      "141786/141786 [==============================] - 4s 27us/step - loss: 0.0017 - r2: 0.1482 - mean_absolute_error: 0.0204\n",
      "Epoch 46/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0016 - r2: 0.1494 - mean_absolute_error: 0.0203\n",
      "Epoch 47/50\n",
      "141786/141786 [==============================] - 3s 22us/step - loss: 0.0016 - r2: 0.1559 - mean_absolute_error: 0.0202\n",
      "Epoch 48/50\n",
      "141786/141786 [==============================] - 4s 27us/step - loss: 0.0016 - r2: 0.1632 - mean_absolute_error: 0.0201\n",
      "Epoch 49/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0016 - r2: 0.1397 - mean_absolute_error: 0.0201\n",
      "Epoch 50/50\n",
      "141786/141786 [==============================] - 3s 21us/step - loss: 0.0016 - r2: 0.1488 - mean_absolute_error: 0.0201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12979e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=50, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47262/47262 [==============================] - 1s 15us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.006582647016144493, -6.734042973268361, 0.042732740269968275]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
