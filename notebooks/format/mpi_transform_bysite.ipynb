{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from mpi4py import MPI\n",
    "#import plac\n",
    "import os\n",
    "import sys\n",
    "\n",
    "HOUSTON = {'48_201_0051': {'Longitude': -95.474167, 'Latitude': 29.623889},\n",
    "           '48_201_0558': {'Longitude': -95.3536111, 'Latitude': 29.5894444},\n",
    "           '48_201_0572': {'Longitude': -95.105, 'Latitude': 29.583333},\n",
    "           '48_201_0551': {'Longitude': -95.1602778, 'Latitude': 29.8586111},\n",
    "           '48_201_6000': {'Longitude': -95.2535982, 'Latitude': 29.6843603},\n",
    "           '48_201_0669': {'Longitude': -95.252778, 'Latitude': 29.694722},\n",
    "           '48_201_0695': {'Longitude': -95.3414, 'Latitude': 29.7176},\n",
    "           '48_201_0307': {'Longitude': -95.2599093, 'Latitude': 29.718799},\n",
    "           '48_201_0670': {'Longitude': -95.257222, 'Latitude': 29.701944},\n",
    "           '48_201_0673': {'Longitude': -95.256697, 'Latitude': 29.7023},\n",
    "           '48_201_0671': {'Longitude': -95.255, 'Latitude': 29.706111},\n",
    "           '48_201_0069': {'Longitude': -95.2611301, 'Latitude': 29.7062492},\n",
    "           '48_201_1035': {'Longitude': -95.2575931, 'Latitude': 29.7337263},\n",
    "           '48_201_0057': {'Longitude': -95.238469, 'Latitude': 29.734231},\n",
    "           '48_201_1049': {'Longitude': -95.2224669, 'Latitude': 29.716611},\n",
    "           '48_201_0803': {'Longitude': -95.1785379, 'Latitude': 29.7647877},\n",
    "           '48_201_1034': {'Longitude': -95.2205822, 'Latitude': 29.7679965},\n",
    "           '48_201_1052': {'Longitude': -95.38769, 'Latitude': 29.81453},\n",
    "           '48_201_0024': {'Longitude': -95.3261373, 'Latitude': 29.9010364}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df: pd.DataFrame, year: int, fillgps: bool = False, naninvalid: bool = False, dropnan: bool = False, masknan: float = None, fillnan: float = None, aqsnumerical: bool = False, sites = []) -> pd.DataFrame:\n",
    "\n",
    "    if len(sites) > 0:\n",
    "        #drop all sites other than the one requested\n",
    "        df.drop(df[~df['AQS_Code'].isin(list(sites.keys()))].index, inplace=True)\n",
    "\n",
    "    # This is probobly not needed anymore after changes Data_structure_3 (level3_data)\n",
    "    if naninvalid:\n",
    "        if year < 2014:\n",
    "            val = 'VAL'\n",
    "        if year >= 2014:\n",
    "            val = 'K'\n",
    "\n",
    "        df[df['nox_flag'] != val]['nox_flag'] = np.nan\n",
    "        df[df['no_flag'] != val]['no_flag'] = np.nan\n",
    "        df[df['no2_flag'] != val]['no2_flag'] = np.nan\n",
    "        df[df['o3_flag'] != val]['o3_flag'] = np.nan\n",
    "\n",
    "    # This is probobly not needed anymore after changes Data_structure_3 (level3_data)\n",
    "    if fillgps:\n",
    "        unique = df['AQS_Code'].unique()\n",
    "        for site in HOUSTON:\n",
    "            if site in unique:\n",
    "                df[df['AQS_Code'] == site]['Longitude'] = HOUSTON[site]['Longitude']\n",
    "                df[df['AQS_Code'] == site]['Latitude'] = HOUSTON[site]['Latitude']\n",
    "\n",
    "    if dropnan:\n",
    "        if year < 2014:\n",
    "            val = 'VAL'\n",
    "        if year >= 2014:\n",
    "            val = 'K'\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if aqsnumerical:\n",
    "        df['AQS_Code'].str.replace('_', '')\n",
    "        df['AQS_Code'] = df['AQS_Code'].astype(int)\n",
    "\n",
    "    df['wind_x_dir'] = df['windspd'] * np.cos(df['winddir'] * (np.pi / 180))\n",
    "    df['wind_y_dir'] = df['windspd'] * np.sin(df['winddir'] * (np.pi / 180))\n",
    "    df['hour'] = pd.to_datetime(df['epoch'], unit='s').dt.hour\n",
    "    df['day_of_year'] = pd.Series(pd.to_datetime(df['epoch'], unit='s'))\n",
    "    df['day_of_year'] = df['day_of_year'].dt.dayofyear\n",
    "\n",
    "    if masknan is not None:\n",
    "        s = df['AQS_Code']\n",
    "        df[df.isnull().any(axis=1)] = 1000\n",
    "        df['AQS_Code'] = s\n",
    "    elif fillnan is not None:\n",
    "        df.fillna(fillnan, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_job(job: dict):\n",
    "\n",
    "    if job['cmd'] == 'transform':\n",
    "\n",
    "        chunk_idx = 0\n",
    "\n",
    "        for chunk in pd.read_csv(job['input_path'], chunksize=job['chunksize'], low_memory=False):\n",
    "            chunk = transform(chunk, year=job['year'],\n",
    "                              fillgps=job['fillgps'],\n",
    "                              naninvalid=job['naninvalid'],\n",
    "                              dropnan=job['dropnan'],\n",
    "                              masknan=job['masknan'],\n",
    "                              fillnan=job['fillnan'],\n",
    "                              aqsnumerical=job['aqsnumerical'],\n",
    "                              sites=job['sites'])\n",
    "\n",
    "            if chunk_idx == 0:\n",
    "                chunk.to_csv(job['output_path'])\n",
    "            else:\n",
    "                chunk.to_csv(job['output_path'], mode='a', header=False)\n",
    "\n",
    "            chunk_idx += 1\n",
    "\n",
    "\n",
    "@plac.annotations(\n",
    "    input_path=(\"Path containing the data files to ingest\", \"option\", \"p\", str),\n",
    "    input_prefix=(\"{$prefix}year.csv\", \"option\", \"P\", str),\n",
    "    input_suffix=(\"year{$suffix}.csv\", \"option\", \"S\", str),\n",
    "    output_path=(\"Path to write the resulting numpy sequences / transform cache\", \"option\", \"o\", str),\n",
    "    year_begin=(\"First year to process\", \"option\", \"b\", int),\n",
    "    year_end=(\"Year to stop with\", \"option\", \"e\", int),\n",
    "    fillgps=(\"Add correct GPS information because it is often missing in Data_structure_3\", \"flag\", \"G\"),\n",
    "    naninvalid=(\"Set invalid col entries to nan\", \"flag\", \"N\"),\n",
    "    dropnan=(\"Drop nan rows\", \"flag\", \"D\"),\n",
    "    masknan=(\"Mask nan rows\", \"option\", \"M\", float),\n",
    "    fillnan=(\"Fill nan rows\", \"option\", \"F\", float),\n",
    "    aqsnumerical=(\"Convert AQS code to numerical\", \"flag\", \"A\"),\n",
    "    houston=(\"Only run for Houston sites\", \"flag\", \"H\"),\n",
    "    chunksize=(\"Process this many records at one time\", \"option\", 'C', int)\n",
    ")\n",
    "def main(input_path: str = '/project/lindner/air-pollution/level3_data',\n",
    "         input_prefix: str = \"Data_\",\n",
    "         input_suffix: str = \"\",\n",
    "         output_path: str = '/project/lindner/air-pollution/current/2019/data-formatted/houston',\n",
    "         year_begin: int = 2000,\n",
    "         year_end: int = 2018,\n",
    "         fillgps: bool = False,\n",
    "         naninvalid: bool = False,\n",
    "         dropnan: bool = False,\n",
    "         masknan: float = None,\n",
    "         fillnan: float = None,\n",
    "         aqsnumerical: bool = False,\n",
    "         houston: bool = False,\n",
    "         chunksize: int = 200000):\n",
    "\n",
    "    if masknan is not None and fillnan is not None:\n",
    "        sys.exit(\"Error: fillnan and masknan cannot both be set.\")\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    n_procs = comm.Get_size()\n",
    "\n",
    "    print(\"(mpi4py) rank: %d n_procs: %d\" % (rank, n_procs))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if rank == 0:\n",
    "\n",
    "        # Create jobs\n",
    "        jobs = []\n",
    "\n",
    "        for year_idx, year in enumerate(range(year_begin, year_end))\n",
    "            input_name = \"%s%d%s.csv\" % (input_prefix, year, input_suffix)\n",
    "            df = pd.read_csv(input_path+input_name)\n",
    "            unique_aqs = df['AQS_Code'].unique()\n",
    "            for aqs in unique_aqs:\n",
    "                transform_name = 'Transformed_' + input_name+'_'+aqs\n",
    "                job = {'cmd': 'transform',\n",
    "                   'year': year,\n",
    "                   'dropnan': dropnan,\n",
    "                   'fillgps': fillgps,\n",
    "                   'naninvalid': naninvalid,\n",
    "                   'masknan': masknan,\n",
    "                   'fillnan': fillnan,\n",
    "                   'sites': [aqs],\n",
    "                   'aqsnumerical': aqsnumerical,\n",
    "                   'input_path': os.path.join(input_path, input_name),\n",
    "                   'output_path': os.path.join(output_path, transform_name),\n",
    "                   'chunksize': chunksize}\n",
    "\n",
    "                if houston:\n",
    "                    job['sites'] = HOUSTON\n",
    "\n",
    "\n",
    "                jobs.append(job)\n",
    "\n",
    "                outstanding_jobs = 0\n",
    "                n_proc = 1\n",
    "\n",
    "        # Distribute one full round robin of jobs\n",
    "        while len(jobs) > 0:\n",
    "            comm.isend(jobs.pop(), dest=n_proc, tag=1)\n",
    "\n",
    "            n_proc += 1\n",
    "            outstanding_jobs += 1\n",
    "\n",
    "            if n_proc == n_procs:\n",
    "                break\n",
    "\n",
    "        # Distribute more jobs as workers become free\n",
    "        while outstanding_jobs > 0:\n",
    "            req = comm.irecv(tag=2)\n",
    "            data = req.wait()\n",
    "\n",
    "            outstanding_jobs -= 1\n",
    "\n",
    "            if len(jobs) > 0:\n",
    "                comm.isend(jobs.pop(), dest=data['rank'], tag=1)\n",
    "                outstanding_jobs += 1\n",
    "\n",
    "            print(\"%d jobs left.\" % (len(jobs) + outstanding_jobs))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # Clean up\n",
    "        for nproc in range(1, n_procs):\n",
    "            req = comm.isend({'cmd': 'shutdown'}, nproc, tag=1)\n",
    "            req.wait()\n",
    "\n",
    "        print(\"Node %d shutting down.\" % rank)\n",
    "\n",
    "    else:\n",
    "        while True:\n",
    "            req = comm.irecv(source=0, tag=1)\n",
    "            job = req.wait()\n",
    "\n",
    "            if job['cmd'] == 'transform':\n",
    "\n",
    "                print(\"Got job: %s\" % job['year'])\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                run_job(job)\n",
    "\n",
    "                print(\"Finished job: %s\" % job['year'])\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                result = {'year': job['year'], 'rank': rank}\n",
    "                req = comm.isend(result, dest=0, tag=2)\n",
    "                req.wait()\n",
    "\n",
    "            elif job['cmd'] == 'shutdown':\n",
    "                print(\"Node %d shutting down.\" % rank)\n",
    "                sys.stdout.flush()\n",
    "                return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plac.call(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
