{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Local\n",
    "#data=pd.read_csv('d00.csv')\n",
    "data=pd.read_csv('Data_2000_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AQS_Code', 'Latitude', 'Longitude', 'epoch', 'no', 'no2', 'nox', 'o3',\n",
       "       'temp', 'temp_flag', 'winddir', 'windspd', 'hour', 'day', 'month',\n",
       "       'year', 'wind_x_dir', 'wind_y_dir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "data=data.drop(['no2','nox'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strs=data\n",
    "data_strs['day']=data_strs['day'].apply(lambda x: str(x))\n",
    "data_strs['month']=data_strs['month'].apply(lambda x: str(x))\n",
    "data_strs['hour']=data_strs['hour'].apply(lambda x: str(x))\n",
    "data_strs['year']=data_strs['hour'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(data_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(dummies['no'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= dummies.drop('no', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Implementation Time</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 0, verbose=1)\n",
    "#use verbose=1\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Save to file in the current working directory\n",
    "joblib_file = \"rf-no-2000.pkl\"  \n",
    "joblib.dump(rf, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.score(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "kfold = model_selection.KFold(n_splits=4, random_state=0)\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = model_selection.cross_val_score(rf, test_features, test_labels, cv=kfold, scoring=scoring)\n",
    "print('Mean absolute errors: '+str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances=rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(feat_importances,\n",
    "                                   index = dummies.drop('o3', axis=1).columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.to_csv('feat-importances-no.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "rf_reg=RandomForestRegressor()\n",
    "parameters= {'n_estimators':[100], 'max_features':[2,4,8,16,32,64,76], 'min_samples_leaf': [1,10,50,100,200,500], 'min_samples_split': [2,4,8,16]}\n",
    "rf_grid = GridSearchCV(rf_reg, parameters, cv = 4)\n",
    "rf_grid.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_100=rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_100.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file in the current working directory\n",
    "joblib_file = \"rf_100.pkl\"  \n",
    "joblib.dump(rf_100, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf_10.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from file\n",
    "joblib_model = joblib.load(joblib_file)\n",
    "\n",
    "# Calculate the accuracy and predictions\n",
    "score = joblib_model.score(Xtest, Ytest)  \n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "Ypredict = pickle_model.predict(Xtest)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
