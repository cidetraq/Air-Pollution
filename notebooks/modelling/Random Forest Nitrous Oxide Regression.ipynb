{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def concat(year):\n",
    "    filename='Data_'+str(year)+'_ready.csv'\n",
    "    #Local\n",
    "    #filename='d'+year+'.csv'\n",
    "    subset=pd.read_csv(filename)\n",
    "    subset=subset.drop(['nox','temp_flag'], axis=1)\n",
    "    global data\n",
    "    data=pd.concat([data,subset], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "years=np.arange(2000,2014)\n",
    "#Local\n",
    "#years=['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13']\n",
    "data=pd.DataFrame()\n",
    "for year in years:\n",
    "    concat(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('data-ready.csv', index=False)\n",
    "data=pd.read_csv('data-ready.csv', dtype={'AQS_Code': np.object,\n",
    " 'Latitude': 'float64',\n",
    " 'Longitude': 'float64',\n",
    " 'co': 'float64',\n",
    " 'co_flag': 'float64',\n",
    " 'dew': 'float64',\n",
    " 'dew_flag': 'float64',\n",
    " 'epoch': 'int64',\n",
    " 'humid': 'float64',\n",
    " 'humid_flag': 'float64',\n",
    " 'no': 'float64',\n",
    " 'no2': 'float64',\n",
    " 'no2_flag': 'object', \n",
    " 'no_flag': 'object',\n",
    " 'nox': 'float64',\n",
    " 'nox_flag': 'object',\n",
    " 'o3': 'float64',\n",
    " 'o3_flag': 'object',\n",
    " 'pm25': 'float64',\n",
    " 'pm25_flag': 'object',\n",
    " 'redraw': 'float64',\n",
    " 'so2': 'float64',\n",
    " 'so2_flag': 'float64',\n",
    " 'solar': 'float64',\n",
    " 'solar_flag': 'float64',\n",
    " 'temp': 'float64',\n",
    " 'temp_flag': 'object',\n",
    " 'winddir': 'float64',\n",
    " 'winddir_flag': 'object',\n",
    " 'windspd': 'float64',\n",
    " 'windspd_flag': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strs=data\n",
    "data_strs['day']=data_strs['day'].apply(lambda x: str(x))\n",
    "data_strs['month']=data_strs['month'].apply(lambda x: str(x))\n",
    "data_strs['hour']=data_strs['hour'].apply(lambda x: str(x))\n",
    "data_strs['year']=data_strs['hour'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(data_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(dummies['no'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= dummies.drop('no', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Implementation Time</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 0, verbose=1)\n",
    "#use verbose=1\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Save to file in the current working directory\n",
    "joblib_file = \"2000-2013-rf-no.pkl\"  \n",
    "joblib.dump(rf, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.score(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=0)\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = model_selection.cross_val_score(rf, test_features, test_labels, cv=kfold, scoring=scoring)\n",
    "print('Mean absolute errors: '+str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances=rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(feat_importances,\n",
    "                                   index = dummies.drop('o3', axis=1).columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.to_csv('feat-importances-no.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "rf_reg=RandomForestRegressor()\n",
    "parameters= {'n_estimators':[100], 'max_features':[2,4,8,16,32,64,76], 'min_samples_leaf': [1,10,50,100,200,500], 'min_samples_split': [2,4,8,16]}\n",
    "rf_grid = GridSearchCV(rf_reg, parameters, cv = 4)\n",
    "rf_grid.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_100=rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_100.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file in the current working directory\n",
    "joblib_file = \"rf_100.pkl\"  \n",
    "joblib.dump(rf_100, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf_10.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from file\n",
    "joblib_model = joblib.load(joblib_file)\n",
    "\n",
    "# Calculate the accuracy and predictions\n",
    "score = joblib_model.score(Xtest, Ytest)  \n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "Ypredict = pickle_model.predict(Xtest)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
